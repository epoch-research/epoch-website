---
title: Research
---

<head>
	<style>
    .project:hover {
      text-decoration: none;
    }

		.project-list {
      		overflow: hidden;
    	}
		.project {
			vertical-align: top;
			color: #111;
     	height: 100%;
      border-bottom: 1 solid grey;
		}
		.project h3 {
			margin-bottom: 0px;
		}
		.project p {
			color: grey;
		}
		.project-date {
			float: left;
			width: 10%;
			margin-top: 7px;
			margin-right: 1em;
		}
		.project-summary {
			float: left;
			width: 50%;
		}
		.project-thumbnail {
			float: right;
			width: 30%;
		}
		.project-thumbnail img {
			max-width: 100%;
		}
	</style>
</head>

# Research Agenda
_Last update: May 2nd, 2022_ 

## 1 Introduction
The development of Artificial Intelligence has been progressing at a rapid rate - between 2010 and 2022, there has been a 10 billion-fold increase in the compute used to train Machine Learning (ML) systems ([Sevilla et al., 2022](https://arxiv.org/abs/2202.05924)). During this period, there has also been a proliferation of national AI strategies, such as the 2017 Pan-Canadian Artificial Intelligence Strategy ([CIFAR, 2020](https://cifar.ca/wp-content/uploads/2020/11/AICan-2020-CIFAR-Pan-Canadian-AI-Strategy-Impact-Report.pdf)), and China's New Generation Artificial Intelligence Development Plan ([Webster, 2017](https://www.newamerica.org/cybersecurity-initiative/digichina/blog/full-translation-chinas-new-generation-artificial-intelligence-development-plan-2017/)). AI systems are increasingly being deployed across many domains, ranging from social media ([Kreps, 2020](https://www.cambridge.org/core/journals/journal-of-experimental-political-science/article/all-the-news-thats-fit-to-fabricate-aigenerated-text-as-a-tool-of-media-misinformation/40F27F0661B839FA47375F538C19FA59)) to protein folding ([Senior, 2020](https://www.nature.com/articles/s41586-019-1923-7.epdf?author_access_token=Z_KaZKDqtKzbE7Wd5HtwI9RgN0jAjWel9jnR3ZoTv0MCcgAwHMgRx9mvLjNQdB2TlQQaa7l420UCtGo8vYQ39gg8lFWR9mAZtvsN_1PrccXfIbc6e-tGSgazNL_XdtQzn1PHfy21qdcxV7Pw-k3htw%3D%3D)).

Given these developments, it is imperative that researchers and governments pay close attention to the possible risks from AI, such as algorithmic bias and the misuse of AI by malicious actors ([Dafoe, 2018](https://www.fhi.ox.ac.uk/wp-content/uploads/GovAI-Agenda.pdf)). At Epoch, we are particularly concerned about risks arising from **Transformative AI (TAI)** - AI systems that have the potential to have an effect on society as large as that of the industrial revolution ([Karnofsky, 2016](https://www.openphilanthropy.org/blog/some-background-our-views-regarding-advanced-artificial-intelligence)).

There are several reasons for our concern about TAI in particular: 
- **Extremely dual-use nature**: AI today can already be used in harmful ways